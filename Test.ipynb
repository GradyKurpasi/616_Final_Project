{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd048357b9fbc49a04e3ca3e86ac919006533cd361674c1c257698448ceb174da2d",
   "display_name": "Python 3.8.5 64-bit ('AzurePytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Workspace: AzureML-Pytorch\n",
      "Compute Target: AzPytrch-NC6\n",
      "Datastore: workspaceblobstore\n",
      "Experiment: 616_Final\n",
      "Uploading an estimated of 5 files\n",
      "Uploading ./data\\alldonesmall.csv\n",
      "Uploaded ./data\\alldonesmall.csv, 1 files out of an estimated total of 5\n",
      "Uploading ./data\\alldone.csv\n",
      "Uploaded ./data\\alldone.csv, 2 files out of an estimated total of 5\n",
      "Uploading ./data\\test_dl.pt\n",
      "Uploaded ./data\\test_dl.pt, 3 files out of an estimated total of 5\n",
      "Uploading ./data\\Payment_Output.csv\n",
      "Uploaded ./data\\Payment_Output.csv, 4 files out of an estimated total of 5\n",
      "Uploading ./data\\train_dl.pt\n",
      "Uploaded ./data\\train_dl.pt, 5 files out of an estimated total of 5\n",
      "Uploaded 5 files\n",
      "[({\n",
      "  \"name\": \"workspaceblobstore\",\n",
      "  \"container_name\": \"azureml-blobstore-37cc9333-cffe-4a2a-ba89-7ed5c59dd573\",\n",
      "  \"account_name\": \"azuremlpytorch4611169748\",\n",
      "  \"protocol\": \"https\",\n",
      "  \"endpoint\": \"core.windows.net\"\n",
      "}, 'data')]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import azurescript as azs\n",
    "\n",
    "azs.ConnectToAzure()\n",
    "azs.UploadData()\n",
    "azs.CreateAzureDataset()\n",
    "azs.PrepareAzureScript()\n",
    "# azs.RunAzureScript()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (484) must match the size of tensor b (100) at non-singleton dimension 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bfa6fed5d60f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mnum_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (484) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "## LOCAL TEST MODEL\n",
    "import torch\n",
    "import scripts.model as mod\n",
    "import scripts.preprocess as pp\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn.modules.activation import Sigmoid\n",
    "\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lr = .1\n",
    "model = mod.SimpleMLP()\n",
    "train_dl, test_dl = pp.LoadPreProcess()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        # print(xb.float())\n",
    "        # print(type(xb))\n",
    "        pred = model(xb.float())\n",
    "        # print(len(pred))\n",
    "        # print(type(pred))\n",
    "        # print(len(pred[0]))\n",
    "        loss = loss_func(pred, yb.long())\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    last_val_loss = 0\n",
    "    num = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dl:\n",
    "            pred = model(xb.float())\n",
    "            val_loss += loss_func(pred, yb.long())\n",
    "            pred[pred<.5]==0\n",
    "            pred[pred>=.5]==1\n",
    "            num_correct += (pred==yb).sum()\n",
    "            num = len(yb)\n",
    "\n",
    "    print('Loss: ', epoch, val_loss)\n",
    "    print('Accuraccy: ,', num_correct / num)\n",
    "    if last_val_loss > val_loss: print('OVERTRAINING')\n",
    "    last_val_loss = val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Loaded\n",
      "Solution String Created\n",
      "Data Loader Created\n",
      "YAY!\n"
     ]
    }
   ],
   "source": [
    "##LOCAL TEST PREPRPOCESS\n",
    "\n",
    "import scripts.preprocess as pp\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "datapath = \"./data/\"\n",
    "master, payments = pp.LoadData(datapath, filename='alldone.csv')\n",
    "print('Data Loaded')\n",
    "solution, master = pp.PrepMLPData(master, payments)\n",
    "print('Solution String Created')\n",
    "train_dl, test_dl = pp.CreateMLPDataLoader(master, solution)\n",
    "print('Data Loader Created')\n",
    "\n",
    "filename = os.path.join(datapath, 'train_dl.pt')\n",
    "torch.save(train_dl, 'train_dl.pt')\n",
    "filename = os.path.join(datapath, 'test_dl.pt')\n",
    "torch.save(test_dl, 'test_dl.pt')\n",
    "print('YAY!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[8.0000e+00, 2.1101e+05, 3.0857e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [8.0000e+00, 2.2596e+05, 3.2309e+05,  ..., 0.0000e+00, 1.0000e+00,\n         1.0000e+00],\n        [8.0000e+00, 1.8101e+05, 2.7874e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        ...,\n        [8.0000e+00, 1.8083e+05, 2.7855e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [8.0000e+00, 1.9975e+05, 2.9737e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [8.0000e+00, 2.4305e+05, 3.4004e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00]], dtype=torch.float64)\ntensor([[8.0000e+00, 1.9525e+05, 2.9291e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [8.0000e+00, 1.9755e+05, 2.9520e+05,  ..., 1.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [8.0000e+00, 2.2625e+05, 3.2337e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        ...,\n        [8.0000e+00, 2.1404e+05, 3.1160e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [8.0000e+00, 2.1731e+05, 3.1479e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [8.0000e+00, 1.7921e+05, 2.7693e+05,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for x, y in train_dl:\n",
    "    print(x)\n",
    "    n += 1\n",
    "    if n > 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clientname, accountid, customerid, ssnlastfour, Address1, Address2, City, State, PostalCode, dateplaced, placedbalance, dollarscollected, placeddpd, hasbrokenpromise, hasconfirmed, haskeptptp, haspayments, hasplacementphone, haspossiblenumber, haspromever, Month1, Month2]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clientname</th>\n      <th>accountid</th>\n      <th>customerid</th>\n      <th>ssnlastfour</th>\n      <th>Address1</th>\n      <th>Address2</th>\n      <th>City</th>\n      <th>State</th>\n      <th>PostalCode</th>\n      <th>dateplaced</th>\n      <th>...</th>\n      <th>placeddpd</th>\n      <th>hasbrokenpromise</th>\n      <th>hasconfirmed</th>\n      <th>haskeptptp</th>\n      <th>haspayments</th>\n      <th>hasplacementphone</th>\n      <th>haspossiblenumber</th>\n      <th>haspromever</th>\n      <th>Month1</th>\n      <th>Month2</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "master[master['accountid']==24837]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}